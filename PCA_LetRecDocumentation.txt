> #PCA
> 
> #Importing the dataset
> dataset = read.csv("letter-recognition.data")
> 
> #Modifying Data
> dataset = cbind(dataset[c(2:17)], dataset[1])
> str(dataset)
'data.frame':	20000 obs. of  17 variables:
 $ x.box : int  2 5 4 7 2 4 4 1 2 11 ...
 $ y.box : int  8 12 11 11 1 11 2 1 2 15 ...
 $ width : int  3 3 6 6 3 5 5 3 4 13 ...
 $ height: int  5 7 8 6 1 8 4 2 4 9 ...
 $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...
 $ x.bar : int  8 10 10 5 8 8 8 8 10 13 ...
 $ y.bar : int  13 5 6 9 6 8 7 2 6 2 ...
 $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...
 $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...
 $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...
 $ x2ybar: int  10 3 3 4 5 6 6 2 4 1 ...
 $ xy2bar: int  8 9 7 10 9 6 6 8 8 9 ...
 $ x.ege : int  0 2 3 6 1 0 2 1 1 8 ...
 $ xegvy : int  8 8 7 10 7 8 8 6 6 1 ...
 $ y.ege : int  0 4 3 2 5 9 7 2 1 1 ...
 $ yegvx : int  8 10 9 8 10 7 10 7 7 8 ...
 $ letter: Factor w/ 26 levels "A","B","C","D",..: 20 9 4 14 7 19 2 1 10 13 ...
> 
> #Splitting the dataset into Training set and Test set
> library(caTools)
> set.seed(123)
> split = sample.split(dataset$letter, SplitRatio = 0.8)
> training_set = subset(dataset, split == TRUE)
> test_set = subset(dataset, split == FALSE)
> 
> #Feature Scaling
> training_set[-17] = scale(training_set[-17])
> test_set[-17] = scale(test_set[-17])
> 
> #Appling PCA
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> library(e1071)
> pca = preProcess(x = training_set[-17], method = 'pca', thresh = 0.90)
> training_set_pca = predict(pca, training_set)
> training_set_pca = cbind(training_set_pca[c(2:11)], training_set_pca[1])
> test_set_pca = predict(pca, test_set)
> test_set_pca = cbind(test_set_pca[c(2:11)], test_set_pca[1])
> 
> #Fitting SVM to the Training set
> library(e1071)
> classifier = svm(formula = letter~.,
+                  data = training_set_pca,
+                  type = "C-classification",
+                  kernel = "linear")
> 
> #Predicting the Test set Results
> pred = predict(classifier, newdata = test_set_pca[-11])
> 
> #Making the Confusion Matrix
> cm = table(test_set_pca[, 11], pred)
> cm
   pred
      A   B   C   D   E   F   G   H   I   J   K   L   M   N   O   P   Q   R   S   T   U   V
  A 142   0   0   2   0   0   0   0   0   3   1   0   0   3   0   0   1   3   0   0   1   0
  B   0 104   0   7   0   0   4   3   2   0   0   0   0   0   2   0   0  16  12   0   0   0
  C   3   0 115   0   8   2   6   0   0   0   5   0   0   0   2   0   0   0   0   2   3   0
  D   1   3   0 135   0   0   0   1   0   1   0   0   0   4   4   1   0   5   1   1   1   0
  E   0   0   1   0 105   1   7   0   1   0   2   2   0   0   0   0   2   0  16   3   0   0
  F   0   3   2   1   2 118   1   0   0   0   1   0   0   4   0  10   0   0   1  11   0   0
  G   0   3  13   4   2   2  90   2   2   0   5   0   2   2   0   1  16   4   2   0   0   2
  H   0   3   0  15   0   2   3  81   0   0   8   0   0   9   8   2   0   8   1   0   1   2
  I   2   2   1   2   0   3   0   0 125   6   0   3   0   0   0   1   0   0   5   0   0   0
  J   4   0   0   7   0   0   0   0   4 119   0   0   0   1   5   0   0   0   6   0   0   0
  K   0   0   8   4   1   0   1   2   0   0 113   3   0   0   0   0   1  12   0   0   0   1
  L   2   0   0   0   8   0   5   1   0   4   1 119   0   0   0   0   3   0   3   1   0   0
  M   2   3   0   0   0   0   1   0   0   0   0   0 141   4   0   0   1   2   0   0   0   0
  N   3   0   0   4   0   0   0   0   0   0   1   0   1 134   3   0   0   1   0   0   5   2
  O   3   0   0  13   0   0   0  11   0   0   0   0   1   1  98   3  10   3   1   0   2   0
  P   0   2   0   0   1  10   4   1   1   0   1   0   0   0   0 139   0   0   0   0   0   0
  Q   4   0   0   0   4   0   8   0   0   0   1   2   0   0   3   0 120   4   6   0   0   2
  R   4   5   0   6   0   0   1   1   0   0   8   0   1   3   2   0   0 114   3   0   1   1
  S   3  16   0   0   3   1   1   5   2   2   0   5   0   0   0   0   4   0  93   6   0   0
  T   1   0   1   0   1   6   7   2   0   0   4   1   0   1   0   0   1   1   2 111   0   0
  U   2   0   0   0   0   0   0   1   0   0   0   0   4   3   1   0   0   2   0   0 149   0
  V   0   0   0   0   0   1   1   2   0   0   0   0   1   1   0   0   0   1   0   1   0 136
  W   1   1   0   0   0   0   0   1   0   0   0   0   6   0   6   0   0   0   0   0   0   1
  X   0   0   0   7   3   1   5   4   4   0   4   1   0   0   0   0   0   0   6   4   2   0
  Y   2   0   0   1   0   5   0   0   0   0   0   0   0   4   0   2   3   0   1  24   1  18
  Z   0   0   0   5   1   0   0   0   1   1   0   0   0   0   0   0   0   0  33   5   0   0
   pred
      W   X   Y   Z
  A   0   0   2   0
  B   0   3   0   0
  C   0   1   0   0
  D   0   1   0   2
  E   0  10   0   4
  F   0   0   1   0
  G   1   2   0   0
  H   0   4   0   0
  I   0   1   0   0
  J   0   0   0   3
  K   0   2   0   0
  L   0   3   2   0
  M   4   0   0   0
  N   2   0   1   0
  O   5   0   0   0
  P   0   0   2   0
  Q   1   0   1   1
  R   0   2   0   0
  S   0   2   0   7
  T   0   3  17   0
  U   1   0   0   0
  V   2   0   7   0
  W 134   0   0   0
  X   0 116   0   0
  Y   0   0  96   0
  Z   0   1   0 100
> sum(diag(cm))/sum(cm)
[1] 0.7613693
> 
> #Ploting PCAs
> library(ggfortify)
> df <- training_set[-17]
> autoplot(prcomp(df), data = training_set, colour = 'letter', loadings = TRUE,
+          loadings.colour = 'black', loadings.label = TRUE, loadings.label.size = 5,
+          loadings.label.colour = "blue")
> 
> #Bi-Plot
> library(devtools)
> dev.off()
null device 
          1 
> #install_github("fawda123/ggord")
> library(ggord)
> ord <- prcomp(training_set[-17])
> ggord(ord, training_set$letter)